\begin{abstract}
    Submodular extensions of an energy function can be used to efficiently
    compute approximate marginals via variational inference. The accuracy of
    the marginals depends crucially on the quality of the submodular extension.
    To identify the best possible extension, we show an equivalence between the
    submodular extensions of the energy and the objective functions of linear
    programming (LP) relaxations for the corresponding MAP estimation problem.
    This allows us to (i) establish the worst-case optimality of the submodular
    extension for Potts model used in the literature; (ii) identify the
    worst-case optimal submodular extension for the more general class of
    metric labeling; (iii) efficiently compute the marginals for the widely
    used dense CRF model with the help of a recently proposed Gaussian
    filtering method; and (iv) identify the submodular extension based on an LP
    relaxation for the higher-order Potts model. Using synthetic and real data, we show that our approach provides comparable upper bounds on the log-partition function to those obtained using tree-reweighted message passing (TRW) in cases where the latter is computationally feasible. Importantly, unlike TRW, our approach provides the first practical algorithm to compute an upper bound on the dense CRF model.
\end{abstract}


